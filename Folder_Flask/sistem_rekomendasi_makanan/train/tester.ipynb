{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c4bae91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.feature_selection import SelectKBest \n",
    "from sklearn.feature_selection import chi2 \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from math import sqrt\n",
    "import pickle\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a56d1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ayam = pd.read_csv('dataset-ayam.csv')\n",
    "ikan = pd.read_csv('dataset-ikan.csv')\n",
    "kambing = pd.read_csv('dataset-kambing.csv')\n",
    "sapi = pd.read_csv('dataset-sapi.csv')\n",
    "tahu = pd.read_csv('dataset-tahu.csv')\n",
    "telur = pd.read_csv('dataset-telur.csv')\n",
    "tempe = pd.read_csv('dataset-tempe.csv')\n",
    "udang = pd.read_csv('dataset-udang.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "461d3e3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aryasatya\\AppData\\Local\\Temp\\ipykernel_22148\\3628990811.py:1: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = ayam[:13].append([ikan[:13],kambing[:13],sapi[:13],tahu[:13],telur[:13],tempe[:13],udang[:13]])\n"
     ]
    }
   ],
   "source": [
    "df = ayam[:13].append([ikan[:13],kambing[:13],sapi[:13],tahu[:13],telur[:13],tempe[:13],udang[:13]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "142ed6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e050ed84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title          0\n",
      "Ingredients    0\n",
      "Steps          0\n",
      "Loves          0\n",
      "URL            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "a = df.isnull().sum()\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d86fb04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['Loves', 'URL'],axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d71092b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeWords(text):   \n",
    "    text = text.lower()                      \n",
    "    text = re.sub(r'[^\\w\\s]',\"  \", text)     \n",
    "    text = text.strip()\n",
    "    text = re.sub(r'[-+]?[0-9]+', '', text)   \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8aced27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def case_folding(text):\n",
    "    text = text.lower()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd7cd993",
   "metadata": {},
   "outputs": [],
   "source": [
    "key_norm = pd.read_csv('key_norm_merge.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dbe7886b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_normalize(text):\n",
    "    text = ' '.join([key_norm[key_norm['singkat'] == word]['hasil'].values[0] if (key_norm['singkat'] == word).any() else word for word in text.split()])\n",
    "    text = str.lower(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "26a78045",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_ind = stopwords.words('indonesian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6da4e1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "more_stopword = ['kg', 'secukupnya', 'selera']                   \n",
    "\n",
    "stopwords_ind = stopwords_ind + more_stopword\n",
    "\n",
    "def remove_stop_words(text):\n",
    "    clean_words = []\n",
    "    text = text.split()\n",
    "    for word in text:\n",
    "        if word not in stopwords_ind:\n",
    "            clean_words.append(word)\n",
    "    return ' '.join(clean_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0d48cce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "factory = StemmerFactory()\n",
    "stemmer = factory.create_stemmer()\n",
    "\n",
    "def stemming(text):\n",
    "    text = stemmer.stem(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d8e0a2ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw data\t\t:  1 piring nasi--¹/⁴ fillet ayam, potong kotak, cuci bersih--Daun pisang yang sudah dibersihkan--Lidi/tusuk gigi untuk mengapit daun--1 lbr daun salam--3 cm serai, memarkan--1 ikat daun kemangi, opsional--1 cabe merah besar, iris tipis--1 sdt kecap manis--Minyak untuk menumis--100 ml air--Bumbu Halus:--1 cabe merah besar--3 cabe kecil--2 siung bawang merah--1 siung bawang putih--1 kemiri--1 cm kunyit--¹/² ruas jahe--¹/⁴ tomat--1 sdt gula pasir--1 blok kaldu ayam (aku biasa pake maggy) pake royco, masako--Merica (dikira2 z takar nya, aku sdkit z sih)--\n",
      "Remove Words\t\t:   piring nasi    ¹  ⁴ fillet ayam   potong kotak   cuci bersih    daun pisang yang sudah dibersihkan    lidi  tusuk gigi untuk mengapit daun     lbr daun salam     cm serai   memarkan     ikat daun kemangi   opsional     cabe merah besar   iris tipis     sdt kecap manis    minyak untuk menumis     ml air    bumbu halus       cabe merah besar     cabe kecil     siung bawang merah     siung bawang putih     kemiri     cm kunyit    ¹  ² ruas jahe    ¹  ⁴ tomat     sdt gula pasir     blok kaldu ayam   aku biasa pake maggy   pake royco   masako    merica   dikira z takar nya   aku sdkit z sih\n",
      "Stopword removal\t:  piring nasi ¹ ⁴ fillet ayam potong kotak cuci bersih daun pisang dibersihkan lidi tusuk gigi mengapit daun lbr daun salam cm serai memarkan ikat daun kemangi opsional cabe merah iris tipis sdt kecap manis minyak menumis ml air bumbu halus cabe merah cabe siung bawang merah siung bawang putih kemiri cm kunyit ¹ ² ruas jahe ¹ ⁴ tomat sdt gula pasir blok kaldu ayam pake maggy pake royco masako merica z takar nya sdkit z sih\n",
      "Stemming\t\t:  piring nasi fillet ayam potong kotak cuci bersih daun pisang bersih lidi tusuk gigi apit daun lbr daun salam cm serai memar ikat daun kemangi opsional cabe merah iris tipis sdt kecap manis minyak tum ml air bumbu halus cabe merah cabe siung bawang merah siung bawang putih kemiri cm kunyit ruas jahe tomat sdt gula pasir blok kaldu ayam pake maggy pake royco masako merica z takar nya sdkit z sih\n"
     ]
    }
   ],
   "source": [
    "raw_sample = df['Ingredients'].iloc[5]\n",
    "remove_words = removeWords(raw_sample)\n",
    "stopword_removal = remove_stop_words(remove_words)\n",
    "text_stemming = stemming(stopword_removal)\n",
    "\n",
    "print('Raw data\\t\\t: ', raw_sample)\n",
    "print('Remove Words\\t\\t: ', remove_words)\n",
    "print('Stopword removal\\t: ', stopword_removal)\n",
    "print('Stemming\\t\\t: ', text_stemming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f0e53afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_preprocessing_process(text):\n",
    "    text = removeWords(text)\n",
    "    text = text_normalize(text)\n",
    "    text = remove_stop_words(text)\n",
    "    text = stemming(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9cb92b98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 13 s\n",
      "Wall time: 13 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df['clean_teks'] = df['Ingredients'].apply(text_preprocessing_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ba748924",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('clean_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e5183b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['clean_teks']\n",
    "y = df['Ingredients']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "44098c12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer()"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tf_idf_X = TfidfVectorizer(ngram_range=(1,1))\n",
    "tf_idf_X.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9db0b179",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.21879812,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tf_idf = tf_idf_X.transform(X).toarray()\n",
    "X_tf_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a2c4727f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abc</th>\n",
       "      <th>acar</th>\n",
       "      <th>adas</th>\n",
       "      <th>adon</th>\n",
       "      <th>air</th>\n",
       "      <th>al</th>\n",
       "      <th>ambil</th>\n",
       "      <th>amis</th>\n",
       "      <th>an</th>\n",
       "      <th>angciu</th>\n",
       "      <th>...</th>\n",
       "      <th>utama</th>\n",
       "      <th>utuh</th>\n",
       "      <th>vaname</th>\n",
       "      <th>vetsin</th>\n",
       "      <th>wajib</th>\n",
       "      <th>wedges</th>\n",
       "      <th>wijen</th>\n",
       "      <th>wortel</th>\n",
       "      <th>ya</th>\n",
       "      <th>zaitun</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.117864</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.091114</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.218798</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.176830</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.117644</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.328494</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.113208</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.115222</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>103 rows × 479 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     abc  acar  adas  adon       air   al  ambil  amis   an  angciu  ...  \\\n",
       "0    0.0   0.0   0.0   0.0  0.117864  0.0    0.0   0.0  0.0     0.0  ...   \n",
       "1    0.0   0.0   0.0   0.0  0.091114  0.0    0.0   0.0  0.0     0.0  ...   \n",
       "2    0.0   0.0   0.0   0.0  0.176830  0.0    0.0   0.0  0.0     0.0  ...   \n",
       "3    0.0   0.0   0.0   0.0  0.000000  0.0    0.0   0.0  0.0     0.0  ...   \n",
       "4    0.0   0.0   0.0   0.0  0.000000  0.0    0.0   0.0  0.0     0.0  ...   \n",
       "..   ...   ...   ...   ...       ...  ...    ...   ...  ...     ...  ...   \n",
       "98   0.0   0.0   0.0   0.0  0.117644  0.0    0.0   0.0  0.0     0.0  ...   \n",
       "99   0.0   0.0   0.0   0.0  0.113208  0.0    0.0   0.0  0.0     0.0  ...   \n",
       "100  0.0   0.0   0.0   0.0  0.115222  0.0    0.0   0.0  0.0     0.0  ...   \n",
       "101  0.0   0.0   0.0   0.0  0.000000  0.0    0.0   0.0  0.0     0.0  ...   \n",
       "102  0.0   0.0   0.0   0.0  0.000000  0.0    0.0   0.0  0.0     0.0  ...   \n",
       "\n",
       "     utama  utuh    vaname  vetsin  wajib  wedges  wijen  wortel        ya  \\\n",
       "0      0.0   0.0  0.000000     0.0    0.0     0.0    0.0     0.0  0.000000   \n",
       "1      0.0   0.0  0.000000     0.0    0.0     0.0    0.0     0.0  0.218798   \n",
       "2      0.0   0.0  0.000000     0.0    0.0     0.0    0.0     0.0  0.000000   \n",
       "3      0.0   0.0  0.000000     0.0    0.0     0.0    0.0     0.0  0.000000   \n",
       "4      0.0   0.0  0.000000     0.0    0.0     0.0    0.0     0.0  0.000000   \n",
       "..     ...   ...       ...     ...    ...     ...    ...     ...       ...   \n",
       "98     0.0   0.0  0.328494     0.0    0.0     0.0    0.0     0.0  0.000000   \n",
       "99     0.0   0.0  0.000000     0.0    0.0     0.0    0.0     0.0  0.000000   \n",
       "100    0.0   0.0  0.000000     0.0    0.0     0.0    0.0     0.0  0.000000   \n",
       "101    0.0   0.0  0.000000     0.0    0.0     0.0    0.0     0.0  0.000000   \n",
       "102    0.0   0.0  0.000000     0.0    0.0     0.0    0.0     0.0  0.000000   \n",
       "\n",
       "     zaitun  \n",
       "0       0.0  \n",
       "1       0.0  \n",
       "2       0.0  \n",
       "3       0.0  \n",
       "4       0.0  \n",
       "..      ...  \n",
       "98      0.0  \n",
       "99      0.0  \n",
       "100     0.0  \n",
       "101     0.0  \n",
       "102     0.0  \n",
       "\n",
       "[103 rows x 479 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_tf_idf_X = pd.DataFrame(X_tf_idf, columns=tf_idf_X.get_feature_names_out())\n",
    "data_tf_idf_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "65fc2fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tf_idf_feature.pickle', 'wb') as output:\n",
    "    pickle.dump(X_tf_idf, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7c462ab0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer()"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf_y = TfidfVectorizer(ngram_range=(1,1))\n",
    "tf_idf_y.fit(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b493d929",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.30065928, 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.13305151, 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.2091175 , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_tf_idf = tf_idf_y.transform(y).toarray()\n",
    "y_tf_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d2a17d32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>1000</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>15</th>\n",
       "      <th>150</th>\n",
       "      <th>180</th>\n",
       "      <th>1kg</th>\n",
       "      <th>20</th>\n",
       "      <th>...</th>\n",
       "      <th>vaname</th>\n",
       "      <th>vetsin</th>\n",
       "      <th>wajib</th>\n",
       "      <th>wedges</th>\n",
       "      <th>wijen</th>\n",
       "      <th>wortel</th>\n",
       "      <th>ya</th>\n",
       "      <th>yang</th>\n",
       "      <th>yg</th>\n",
       "      <th>zaitun</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.300659</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.23756</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.16285</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.167403</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.293614</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.147020</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.23233</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.133052</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>0.209118</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>103 rows × 643 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           10       100  1000       12   13   15      150  180  1kg   20  ...  \\\n",
       "0    0.300659  0.000000   0.0  0.23756  0.0  0.0  0.00000  0.0  0.0  0.0  ...   \n",
       "1    0.000000  0.000000   0.0  0.00000  0.0  0.0  0.00000  0.0  0.0  0.0  ...   \n",
       "2    0.000000  0.000000   0.0  0.00000  0.0  0.0  0.00000  0.0  0.0  0.0  ...   \n",
       "3    0.000000  0.167403   0.0  0.00000  0.0  0.0  0.00000  0.0  0.0  0.0  ...   \n",
       "4    0.000000  0.000000   0.0  0.00000  0.0  0.0  0.00000  0.0  0.0  0.0  ...   \n",
       "..        ...       ...   ...      ...  ...  ...      ...  ...  ...  ...  ...   \n",
       "98   0.000000  0.000000   0.0  0.00000  0.0  0.0  0.00000  0.0  0.0  0.0  ...   \n",
       "99   0.147020  0.000000   0.0  0.00000  0.0  0.0  0.23233  0.0  0.0  0.0  ...   \n",
       "100  0.133052  0.000000   0.0  0.00000  0.0  0.0  0.00000  0.0  0.0  0.0  ...   \n",
       "101  0.000000  0.000000   0.0  0.00000  0.0  0.0  0.00000  0.0  0.0  0.0  ...   \n",
       "102  0.209118  0.000000   0.0  0.00000  0.0  0.0  0.00000  0.0  0.0  0.0  ...   \n",
       "\n",
       "       vaname  vetsin  wajib  wedges  wijen  wortel       ya  yang   yg  \\\n",
       "0    0.000000     0.0    0.0     0.0    0.0     0.0  0.00000   0.0  0.0   \n",
       "1    0.000000     0.0    0.0     0.0    0.0     0.0  0.16285   0.0  0.0   \n",
       "2    0.000000     0.0    0.0     0.0    0.0     0.0  0.00000   0.0  0.0   \n",
       "3    0.000000     0.0    0.0     0.0    0.0     0.0  0.00000   0.0  0.0   \n",
       "4    0.000000     0.0    0.0     0.0    0.0     0.0  0.00000   0.0  0.0   \n",
       "..        ...     ...    ...     ...    ...     ...      ...   ...  ...   \n",
       "98   0.293614     0.0    0.0     0.0    0.0     0.0  0.00000   0.0  0.0   \n",
       "99   0.000000     0.0    0.0     0.0    0.0     0.0  0.00000   0.0  0.0   \n",
       "100  0.000000     0.0    0.0     0.0    0.0     0.0  0.00000   0.0  0.0   \n",
       "101  0.000000     0.0    0.0     0.0    0.0     0.0  0.00000   0.0  0.0   \n",
       "102  0.000000     0.0    0.0     0.0    0.0     0.0  0.00000   0.0  0.0   \n",
       "\n",
       "     zaitun  \n",
       "0       0.0  \n",
       "1       0.0  \n",
       "2       0.0  \n",
       "3       0.0  \n",
       "4       0.0  \n",
       "..      ...  \n",
       "98      0.0  \n",
       "99      0.0  \n",
       "100     0.0  \n",
       "101     0.0  \n",
       "102     0.0  \n",
       "\n",
       "[103 rows x 643 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_tf_idf_y = pd.DataFrame(y_tf_idf, columns=tf_idf_y.get_feature_names_out())\n",
    "data_tf_idf_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8f991d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(data_tf_idf_X)\n",
    "# y = np.array(data_tf_idf_y)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d0336fb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original feature number: 479\n",
      "Reduced feature number: 479\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest \n",
    "from sklearn.feature_selection import chi2 \n",
    "\n",
    "# Ten features with highest chi-squared statistics are selected \n",
    "chi2_features = SelectKBest(chi2, k='all') \n",
    "X_kbest_features = chi2_features.fit_transform(X, y) \n",
    "  \n",
    "# Reduced features \n",
    "print('Original feature number:', X.shape[1]) \n",
    "print('Reduced feature number:', X_kbest_features.shape[1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8b16cbd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_chi2 = pd.DataFrame(chi2_features.scores_, columns=['nilai'])\n",
    "feature = tf_idf_X.get_feature_names_out()\n",
    "data_chi2['fitur'] = feature\n",
    "mask = chi2_features.get_support()\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7b1a89ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abc',\n",
       " 'acar',\n",
       " 'adas',\n",
       " 'adon',\n",
       " 'air',\n",
       " 'al',\n",
       " 'ambil',\n",
       " 'amis',\n",
       " 'an',\n",
       " 'angciu',\n",
       " 'anis',\n",
       " 'anise',\n",
       " 'api',\n",
       " 'apit',\n",
       " 'arah',\n",
       " 'asa',\n",
       " 'asam',\n",
       " 'asin',\n",
       " 'asli',\n",
       " 'avocado',\n",
       " 'awang',\n",
       " 'ayak',\n",
       " 'ayam',\n",
       " 'baba',\n",
       " 'babat',\n",
       " 'babom',\n",
       " 'bag',\n",
       " 'bahan',\n",
       " 'bakar',\n",
       " 'baking',\n",
       " 'bakso',\n",
       " 'bakwan',\n",
       " 'balur',\n",
       " 'bamer',\n",
       " 'bango',\n",
       " 'banyak',\n",
       " 'baput',\n",
       " 'barbeque',\n",
       " 'basah',\n",
       " 'basil',\n",
       " 'batagor',\n",
       " 'batang',\n",
       " 'batu',\n",
       " 'bau',\n",
       " 'bawang',\n",
       " 'bawng',\n",
       " 'bb',\n",
       " 'bebek',\n",
       " 'beef',\n",
       " 'beli',\n",
       " 'belimbing',\n",
       " 'beras',\n",
       " 'bersih',\n",
       " 'bh',\n",
       " 'biar',\n",
       " 'bihun',\n",
       " 'biji',\n",
       " 'black',\n",
       " 'blender',\n",
       " 'blok',\n",
       " 'bngkus',\n",
       " 'bombai',\n",
       " 'bombang',\n",
       " 'bombay',\n",
       " 'bonggol',\n",
       " 'bongkol',\n",
       " 'botol',\n",
       " 'bread',\n",
       " 'broiler',\n",
       " 'brokoli',\n",
       " 'brown',\n",
       " 'btng',\n",
       " 'btr',\n",
       " 'buah',\n",
       " 'buang',\n",
       " 'bubuk',\n",
       " 'bulat',\n",
       " 'bumbu',\n",
       " 'buncir',\n",
       " 'buncis',\n",
       " 'bunga',\n",
       " 'bungkul',\n",
       " 'bungkus',\n",
       " 'butir',\n",
       " 'bwg',\n",
       " 'bwng',\n",
       " 'cabai',\n",
       " 'cacah',\n",
       " 'cage',\n",
       " 'cair',\n",
       " 'campur',\n",
       " 'cc',\n",
       " 'ceker',\n",
       " 'cemplung',\n",
       " 'cengek',\n",
       " 'cengjeh',\n",
       " 'cengkeh',\n",
       " 'cepat',\n",
       " 'cheddar',\n",
       " 'cheedar',\n",
       " 'chunks',\n",
       " 'cicang',\n",
       " 'cincang',\n",
       " 'cooking',\n",
       " 'cream',\n",
       " 'crispy',\n",
       " 'crumb',\n",
       " 'cuci',\n",
       " 'dada',\n",
       " 'dadu',\n",
       " 'daging',\n",
       " 'daun',\n",
       " 'delmonte',\n",
       " 'dente',\n",
       " 'diameter',\n",
       " 'digeprek',\n",
       " 'dingin',\n",
       " 'ebi',\n",
       " 'egg',\n",
       " 'ekor',\n",
       " 'empuk',\n",
       " 'enak',\n",
       " 'es',\n",
       " 'filet',\n",
       " 'fillet',\n",
       " 'fonte',\n",
       " 'full',\n",
       " 'ganti',\n",
       " 'garam',\n",
       " 'garamsecukupnya',\n",
       " 'garan',\n",
       " 'gelas',\n",
       " 'gendot',\n",
       " 'genggam',\n",
       " 'geprek',\n",
       " 'gigi',\n",
       " 'giling',\n",
       " 'gls',\n",
       " 'goreng',\n",
       " 'gr',\n",
       " 'gram',\n",
       " 'gula',\n",
       " 'gurame',\n",
       " 'habis',\n",
       " 'halu',\n",
       " 'halus',\n",
       " 'helai',\n",
       " 'hihi',\n",
       " 'hihihi',\n",
       " 'hijau',\n",
       " 'hilang',\n",
       " 'hintalu',\n",
       " 'hitam',\n",
       " 'hoby',\n",
       " 'hulu',\n",
       " 'iga',\n",
       " 'ikan',\n",
       " 'ikat',\n",
       " 'india',\n",
       " 'indofo',\n",
       " 'inggris',\n",
       " 'instan',\n",
       " 'instant',\n",
       " 'iris',\n",
       " 'isi',\n",
       " 'jagung',\n",
       " 'jahe',\n",
       " 'jamur',\n",
       " 'jantung',\n",
       " 'jari',\n",
       " 'jaruk',\n",
       " 'jawa',\n",
       " 'jengkol',\n",
       " 'jeroan',\n",
       " 'jeruk',\n",
       " 'jinten',\n",
       " 'jumbo',\n",
       " 'jumput',\n",
       " 'kacang',\n",
       " 'kakap',\n",
       " 'kaki',\n",
       " 'kaldu',\n",
       " 'kaleng',\n",
       " 'kambing',\n",
       " 'kampung',\n",
       " 'kancing',\n",
       " 'kandis',\n",
       " 'kanji',\n",
       " 'kapulaga',\n",
       " 'kara',\n",
       " 'karageenan',\n",
       " 'kari',\n",
       " 'kasar',\n",
       " 'kating',\n",
       " 'kayu',\n",
       " 'kecap',\n",
       " 'keju',\n",
       " 'kelapa',\n",
       " 'kelingking',\n",
       " 'kemangi',\n",
       " 'kemas',\n",
       " 'kembang',\n",
       " 'kembung',\n",
       " 'kemiri',\n",
       " 'kental',\n",
       " 'kentang',\n",
       " 'kenyal',\n",
       " 'kepala',\n",
       " 'keping',\n",
       " 'kering',\n",
       " 'keriting',\n",
       " 'ketumbar',\n",
       " 'klabet',\n",
       " 'ko',\n",
       " 'kobe',\n",
       " 'kocok',\n",
       " 'koja',\n",
       " 'kol',\n",
       " 'korek',\n",
       " 'kornet',\n",
       " 'kotak',\n",
       " 'kriting',\n",
       " 'kriuk',\n",
       " 'kuah',\n",
       " 'kubis',\n",
       " 'kucai',\n",
       " 'kue',\n",
       " 'kukus',\n",
       " 'kulit',\n",
       " 'kunci',\n",
       " 'kuning',\n",
       " 'kunir',\n",
       " 'kuntum',\n",
       " 'kunyit',\n",
       " 'kupas',\n",
       " 'kuping',\n",
       " 'la',\n",
       " 'labu',\n",
       " 'lada',\n",
       " 'lalap',\n",
       " 'laos',\n",
       " 'lap',\n",
       " 'larut',\n",
       " 'lawan',\n",
       " 'lawang',\n",
       " 'leaves',\n",
       " 'lele',\n",
       " 'lem',\n",
       " 'lemak',\n",
       " 'lembar',\n",
       " 'lemon',\n",
       " 'lengkap',\n",
       " 'lengkuas',\n",
       " 'lepas',\n",
       " 'lettuce',\n",
       " 'libur',\n",
       " 'lidi',\n",
       " 'limau',\n",
       " 'linguine',\n",
       " 'liter',\n",
       " 'lombok',\n",
       " 'ltr',\n",
       " 'lumpia',\n",
       " 'lumur',\n",
       " 'lupa',\n",
       " 'maezena',\n",
       " 'maggy',\n",
       " 'maizena',\n",
       " 'makan',\n",
       " 'manggoreng',\n",
       " 'manis',\n",
       " 'marah',\n",
       " 'margarin',\n",
       " 'margarine',\n",
       " 'masak',\n",
       " 'masako',\n",
       " 'matang',\n",
       " 'mayonaise',\n",
       " 'mayumi',\n",
       " 'me',\n",
       " 'meizena',\n",
       " 'memar',\n",
       " 'menit',\n",
       " 'mentega',\n",
       " 'merah',\n",
       " 'merica',\n",
       " 'merk',\n",
       " 'mersh',\n",
       " 'mie',\n",
       " 'minyak',\n",
       " 'miri',\n",
       " 'ml',\n",
       " 'mozarela',\n",
       " 'mrica',\n",
       " 'muda',\n",
       " 'mudah',\n",
       " 'mujaer',\n",
       " 'mutiara',\n",
       " 'my',\n",
       " 'nanas',\n",
       " 'nasi',\n",
       " 'nb',\n",
       " 'nipis',\n",
       " 'numis',\n",
       " 'nya',\n",
       " 'ons',\n",
       " 'opsional',\n",
       " 'oregano',\n",
       " 'otak',\n",
       " 'paha',\n",
       " 'pakai',\n",
       " 'pakcoy',\n",
       " 'pala',\n",
       " 'panas',\n",
       " 'panir',\n",
       " 'panjang',\n",
       " 'papan',\n",
       " 'parmesan',\n",
       " 'parut',\n",
       " 'pasir',\n",
       " 'pasta',\n",
       " 'patin',\n",
       " 'pcs',\n",
       " 'pedas',\n",
       " 'pedesnya',\n",
       " 'peka',\n",
       " 'pekak',\n",
       " 'penuh',\n",
       " 'pepaya',\n",
       " 'pepper',\n",
       " 'petai',\n",
       " 'petis',\n",
       " 'picin',\n",
       " 'pilih',\n",
       " 'pindang',\n",
       " 'pipih',\n",
       " 'piring',\n",
       " 'pisah',\n",
       " 'pisang',\n",
       " 'potong',\n",
       " 'potpng',\n",
       " 'powder',\n",
       " 'prei',\n",
       " 'proteiin',\n",
       " 'purih',\n",
       " 'purut',\n",
       " 'putih',\n",
       " 'racik',\n",
       " 'raja',\n",
       " 'rajang',\n",
       " 'rawit',\n",
       " 'rebus',\n",
       " 'rempah',\n",
       " 'rendam',\n",
       " 'roti',\n",
       " 'royco',\n",
       " 'royko',\n",
       " 'ruas',\n",
       " 'ruku',\n",
       " 'rutinitas',\n",
       " 'sacet',\n",
       " 'sachet',\n",
       " 'sagu',\n",
       " 'saji',\n",
       " 'salada',\n",
       " 'salam',\n",
       " 'sambal',\n",
       " 'sangrai',\n",
       " 'santan',\n",
       " 'saor',\n",
       " 'saori',\n",
       " 'saos',\n",
       " 'sapi',\n",
       " 'sate',\n",
       " 'sauce',\n",
       " 'saus',\n",
       " 'sawi',\n",
       " 'sayap',\n",
       " 'sayur',\n",
       " 'sckpnya',\n",
       " 'sdm',\n",
       " 'sdt',\n",
       " 'seafood',\n",
       " 'sebentar',\n",
       " 'secang',\n",
       " 'seckpnya',\n",
       " 'secukupnnya',\n",
       " 'secukupnyaa',\n",
       " 'sedap',\n",
       " 'seduh',\n",
       " 'segar',\n",
       " 'segitiga',\n",
       " 'selamat',\n",
       " 'seledri',\n",
       " 'semangit',\n",
       " 'sendok',\n",
       " 'serah',\n",
       " 'serai',\n",
       " 'serbaguna',\n",
       " 'sereh',\n",
       " 'serong',\n",
       " 'serta',\n",
       " 'sesuai',\n",
       " 'setan',\n",
       " 'siam',\n",
       " 'siang',\n",
       " 'sih',\n",
       " 'sisir',\n",
       " 'siung',\n",
       " 'skip',\n",
       " 'smooked',\n",
       " 'soda',\n",
       " 'sosis',\n",
       " 'soun',\n",
       " 'spaghetti',\n",
       " 'st',\n",
       " 'star',\n",
       " 'stevia',\n",
       " 'stok',\n",
       " 'strip',\n",
       " 'suami',\n",
       " 'sugar',\n",
       " 'suka',\n",
       " 'sumsum',\n",
       " 'super',\n",
       " 'susu',\n",
       " 'takar',\n",
       " 'tambah',\n",
       " 'tanah',\n",
       " 'tangkai',\n",
       " 'tani',\n",
       " 'taousi',\n",
       " 'taste',\n",
       " 'tauco',\n",
       " 'tauge',\n",
       " 'tebal',\n",
       " 'teh',\n",
       " 'tekwan',\n",
       " 'telur',\n",
       " 'tempe',\n",
       " 'tenggiri',\n",
       " 'tepung',\n",
       " 'terigu',\n",
       " 'teriyaki',\n",
       " 'terong',\n",
       " 'timun',\n",
       " 'tinggal',\n",
       " 'tipis',\n",
       " 'tiram',\n",
       " 'tiris',\n",
       " 'tofu',\n",
       " 'toge',\n",
       " 'tomat',\n",
       " 'tongkol',\n",
       " 'toping',\n",
       " 'tuk',\n",
       " 'tulang',\n",
       " 'tum',\n",
       " 'tuna',\n",
       " 'tusuk',\n",
       " 'udang',\n",
       " 'ujung',\n",
       " 'uk',\n",
       " 'ukep',\n",
       " 'ukur',\n",
       " 'uleg',\n",
       " 'ulek',\n",
       " 'ungu',\n",
       " 'usus',\n",
       " 'utama',\n",
       " 'utuh',\n",
       " 'vaname',\n",
       " 'vetsin',\n",
       " 'wajib',\n",
       " 'wedges',\n",
       " 'wijen',\n",
       " 'wortel',\n",
       " 'ya',\n",
       " 'zaitun']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_feature = []\n",
    "\n",
    "for bool, f in zip(mask, feature):\n",
    "    if bool:\n",
    "        new_feature.append(f)\n",
    "    selected_feature = new_feature\n",
    "\n",
    "selected_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e96cdf71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ekor': 119,\n",
       " 'ayam': 22,\n",
       " 'kampung': 184,\n",
       " 'potong': 339,\n",
       " 'buah': 73,\n",
       " 'jeruk': 174,\n",
       " 'nipis': 302,\n",
       " 'sdm': 380,\n",
       " 'garam': 128,\n",
       " 'ruas': 357,\n",
       " 'kunyit': 233,\n",
       " 'bawang': 44,\n",
       " 'merah': 284,\n",
       " 'putih': 346,\n",
       " 'cabai': 86,\n",
       " 'rawit': 350,\n",
       " 'sesuai': 402,\n",
       " 'butir': 83,\n",
       " 'kemiri': 203,\n",
       " 'batang': 41,\n",
       " 'sereh': 399,\n",
       " 'lembar': 249,\n",
       " 'daun': 111,\n",
       " 'salam': 365,\n",
       " 'ikat': 157,\n",
       " 'kemangi': 199,\n",
       " 'sedap': 388,\n",
       " 'gelas': 131,\n",
       " 'air': 4,\n",
       " 'ya': 477,\n",
       " 'serai': 397,\n",
       " 'memar': 281,\n",
       " 'halus': 145,\n",
       " 'ketumbar': 211,\n",
       " 'jari': 169,\n",
       " 'laos': 240,\n",
       " 'tuk': 455,\n",
       " 'ukep': 463,\n",
       " 'minyak': 289,\n",
       " 'goreng': 138,\n",
       " 'hijau': 149,\n",
       " 'siung': 408,\n",
       " 'gula': 141,\n",
       " 'tomat': 452,\n",
       " 'gr': 139,\n",
       " 'daging': 110,\n",
       " 'pakai': 310,\n",
       " 'fillet': 124,\n",
       " 'tepung': 441,\n",
       " 'serbaguna': 398,\n",
       " 'lalap': 239,\n",
       " 'kol': 217,\n",
       " 'timun': 445,\n",
       " 'panas': 313,\n",
       " 'sambal': 366,\n",
       " 'korek': 218,\n",
       " 'bwg': 84,\n",
       " 'kulit': 228,\n",
       " 'lemak': 248,\n",
       " 'kating': 193,\n",
       " 'cincang': 102,\n",
       " 'kasar': 192,\n",
       " 'jahe': 166,\n",
       " 'geprek': 134,\n",
       " 'ml': 291,\n",
       " 'bubuk': 75,\n",
       " 'piring': 336,\n",
       " 'nasi': 300,\n",
       " 'kotak': 220,\n",
       " 'cuci': 107,\n",
       " 'bersih': 52,\n",
       " 'pisang': 338,\n",
       " 'lidi': 256,\n",
       " 'tusuk': 459,\n",
       " 'gigi': 135,\n",
       " 'apit': 13,\n",
       " 'libur': 255,\n",
       " 'opsional': 306,\n",
       " 'iris': 163,\n",
       " 'tipis': 447,\n",
       " 'sdt': 381,\n",
       " 'kecap': 195,\n",
       " 'manis': 270,\n",
       " 'tum': 457,\n",
       " 'bumbu': 77,\n",
       " 'pasir': 319,\n",
       " 'blok': 59,\n",
       " 'kaldu': 181,\n",
       " 'maggy': 266,\n",
       " 'royco': 355,\n",
       " 'masako': 275,\n",
       " 'merica': 285,\n",
       " 'takar': 426,\n",
       " 'nya': 304,\n",
       " 'sih': 406,\n",
       " 'hintalu': 151,\n",
       " 'jaruk': 170,\n",
       " 'terigu': 442,\n",
       " 'bungkus': 82,\n",
       " 'dada': 108,\n",
       " 'tulang': 456,\n",
       " 'bombay': 63,\n",
       " 'bahan': 27,\n",
       " 'mentega': 283,\n",
       " 'saos': 371,\n",
       " 'teriyaki': 443,\n",
       " 'larut': 242,\n",
       " 'meizena': 280,\n",
       " 'adon': 3,\n",
       " 'basah': 38,\n",
       " 'maizena': 267,\n",
       " 'kering': 209,\n",
       " 'jamur': 167,\n",
       " 'saus': 375,\n",
       " 'tiram': 448,\n",
       " 'blender': 58,\n",
       " 'keju': 196,\n",
       " 'parut': 318,\n",
       " 'cair': 89,\n",
       " 'lengkap': 251,\n",
       " 'buncis': 79,\n",
       " 'wortel': 476,\n",
       " 'kukus': 227,\n",
       " 'dadu': 109,\n",
       " 'balur': 32,\n",
       " 'instan': 161,\n",
       " 'uk': 462,\n",
       " 'campur': 90,\n",
       " 'bb': 46,\n",
       " 'mie': 288,\n",
       " 'proteiin': 343,\n",
       " 'telur': 438,\n",
       " 'sendok': 395,\n",
       " 'secukupnyaa': 387,\n",
       " 'rebus': 351,\n",
       " 'kuah': 223,\n",
       " 'lada': 238,\n",
       " 'lengkuas': 252,\n",
       " 'sawi': 376,\n",
       " 'me': 279,\n",
       " 'lupa': 264,\n",
       " 'cepat': 97,\n",
       " 'bau': 43,\n",
       " 'asam': 16,\n",
       " 'broiler': 68,\n",
       " 'ukur': 464,\n",
       " 'jumbo': 176,\n",
       " 'pilih': 333,\n",
       " 'santan': 368,\n",
       " 'kara': 189,\n",
       " 'kentang': 205,\n",
       " 'biji': 56,\n",
       " 'pala': 312,\n",
       " 'kriting': 221,\n",
       " 'suka': 422,\n",
       " 'pedas': 323,\n",
       " 'rempah': 352,\n",
       " 'kapulaga': 188,\n",
       " 'utama': 469,\n",
       " 'gurame': 142,\n",
       " 'bh': 53,\n",
       " 'giling': 136,\n",
       " 'banyak': 35,\n",
       " 'bombang': 62,\n",
       " 'panjang': 315,\n",
       " 'ikan': 156,\n",
       " 'beras': 51,\n",
       " 'lemon': 250,\n",
       " 'sayur': 378,\n",
       " 'kembung': 202,\n",
       " 'sate': 373,\n",
       " 'kunci': 229,\n",
       " 'mujaer': 296,\n",
       " 'stok': 418,\n",
       " 'habis': 143,\n",
       " 'api': 12,\n",
       " 'bombai': 61,\n",
       " 'makan': 268,\n",
       " 'matang': 276,\n",
       " 'purih': 344,\n",
       " 'cage': 88,\n",
       " 'sacet': 360,\n",
       " 'botol': 66,\n",
       " 'tambah': 427,\n",
       " 'maezena': 265,\n",
       " 'kunir': 231,\n",
       " 'tuna': 458,\n",
       " 'kandis': 186,\n",
       " 'belimbing': 50,\n",
       " 'hulu': 154,\n",
       " 'kaleng': 182,\n",
       " 'chunks': 100,\n",
       " 'avocado': 19,\n",
       " 'zaitun': 478,\n",
       " 'bongkol': 65,\n",
       " 'salada': 364,\n",
       " 'lettuce': 254,\n",
       " 'lele': 246,\n",
       " 'segar': 390,\n",
       " 'margarine': 273,\n",
       " 'tenggiri': 440,\n",
       " 'halu': 144,\n",
       " 'cc': 91,\n",
       " 'kental': 204,\n",
       " 'sagu': 362,\n",
       " 'tani': 430,\n",
       " 'tongkol': 453,\n",
       " 'gendot': 132,\n",
       " 'papan': 316,\n",
       " 'petai': 330,\n",
       " 'patin': 321,\n",
       " 'keriting': 210,\n",
       " 'setan': 403,\n",
       " 'biar': 54,\n",
       " 'utuh': 470,\n",
       " 'digeprek': 115,\n",
       " 'buang': 74,\n",
       " 'tauco': 433,\n",
       " 'asin': 17,\n",
       " 'wijen': 475,\n",
       " 'angciu': 9,\n",
       " 'cengek': 94,\n",
       " 'nb': 301,\n",
       " 'hoby': 153,\n",
       " 'kakap': 179,\n",
       " 'tempe': 439,\n",
       " 'ruku': 358,\n",
       " 'genggam': 133,\n",
       " 'ganti': 127,\n",
       " 'kambing': 183,\n",
       " 'pepaya': 328,\n",
       " 'bamer': 33,\n",
       " 'baput': 36,\n",
       " 'jawa': 171,\n",
       " 'bango': 34,\n",
       " 'limau': 257,\n",
       " 'paha': 309,\n",
       " 'serta': 401,\n",
       " 'mersh': 287,\n",
       " 'klabet': 212,\n",
       " 'jinten': 175,\n",
       " 'kayu': 194,\n",
       " 'cengjeh': 95,\n",
       " 'acar': 1,\n",
       " 'gram': 140,\n",
       " 'btng': 71,\n",
       " 'btr': 72,\n",
       " 'cengkeh': 96,\n",
       " 'bawng': 45,\n",
       " 'bwng': 85,\n",
       " 'mrica': 293,\n",
       " 'seckpnya': 385,\n",
       " 'sumsum': 423,\n",
       " 'amis': 7,\n",
       " 'hilang': 150,\n",
       " 'kacang': 178,\n",
       " 'muda': 294,\n",
       " 'miri': 290,\n",
       " 'kelapa': 197,\n",
       " 'tanah': 428,\n",
       " 'kaki': 180,\n",
       " 'potpng': 340,\n",
       " 'india': 158,\n",
       " 'star': 416,\n",
       " 'anise': 11,\n",
       " 'koja': 216,\n",
       " 'selamat': 392,\n",
       " 'tinggal': 446,\n",
       " 'leaves': 245,\n",
       " 'lumur': 263,\n",
       " 'menit': 282,\n",
       " 'peka': 325,\n",
       " 'segitiga': 391,\n",
       " 'kemas': 200,\n",
       " 'susu': 425,\n",
       " 'purut': 345,\n",
       " 'kari': 191,\n",
       " 'teh': 436,\n",
       " 'sangrai': 367,\n",
       " 'adas': 2,\n",
       " 'diameter': 114,\n",
       " 'iga': 155,\n",
       " 'bakar': 28,\n",
       " 'otak': 308,\n",
       " 'secukupnnya': 386,\n",
       " 'ujung': 461,\n",
       " 'kelingking': 198,\n",
       " 'numis': 303,\n",
       " 'royko': 356,\n",
       " 'garan': 130,\n",
       " 'pekak': 326,\n",
       " 'kembang': 201,\n",
       " 'secang': 384,\n",
       " 'anis': 10,\n",
       " 'sachet': 361,\n",
       " 'stevia': 417,\n",
       " 'st': 415,\n",
       " 'liter': 259,\n",
       " 'mudah': 295,\n",
       " 'empuk': 120,\n",
       " 'nanas': 299,\n",
       " 'jeroan': 173,\n",
       " 'babat': 24,\n",
       " 'usus': 468,\n",
       " 'soun': 413,\n",
       " 'toge': 451,\n",
       " 'seledri': 393,\n",
       " 'sapi': 372,\n",
       " 'uleg': 465,\n",
       " 'saor': 369,\n",
       " 'bunga': 80,\n",
       " 'lawang': 244,\n",
       " 'pipih': 335,\n",
       " 'toping': 454,\n",
       " 'kubis': 224,\n",
       " 'pcs': 322,\n",
       " 'spaghetti': 414,\n",
       " 'la': 236,\n",
       " 'fonte': 125,\n",
       " 'al': 5,\n",
       " 'dente': 113,\n",
       " 'ons': 305,\n",
       " 'lawan': 243,\n",
       " 'arah': 14,\n",
       " 'rendam': 353,\n",
       " 'soda': 411,\n",
       " 'kue': 226,\n",
       " 'black': 57,\n",
       " 'pepper': 329,\n",
       " 'instant': 162,\n",
       " 'merk': 286,\n",
       " 'my': 298,\n",
       " 'taste': 432,\n",
       " 'cicang': 101,\n",
       " 'babom': 25,\n",
       " 'helai': 146,\n",
       " 'pasta': 320,\n",
       " 'linguine': 258,\n",
       " 'strip': 419,\n",
       " 'smooked': 410,\n",
       " 'beef': 48,\n",
       " 'parmesan': 317,\n",
       " 'cheddar': 98,\n",
       " 'awang': 20,\n",
       " 'full': 126,\n",
       " 'cream': 104,\n",
       " 'cooking': 103,\n",
       " 'basil': 39,\n",
       " 'margarin': 272,\n",
       " 'jantung': 168,\n",
       " 'inggris': 160,\n",
       " 'saori': 370,\n",
       " 'vetsin': 472,\n",
       " 'masak': 274,\n",
       " 'delmonte': 112,\n",
       " 'barbeque': 37,\n",
       " 'sauce': 374,\n",
       " 'buncir': 78,\n",
       " 'taousi': 431,\n",
       " 'hitam': 152,\n",
       " 'bungkul': 81,\n",
       " 'kocok': 215,\n",
       " 'siang': 405,\n",
       " 'lumpia': 262,\n",
       " 'lem': 247,\n",
       " 'sckpnya': 379,\n",
       " 'serong': 400,\n",
       " 'batagor': 40,\n",
       " 'kuning': 230,\n",
       " 'kriuk': 222,\n",
       " 'indofo': 159,\n",
       " 'suami': 420,\n",
       " 'ceker': 92,\n",
       " 'ko': 213,\n",
       " 'tofu': 450,\n",
       " 'filet': 123,\n",
       " 'jagung': 165,\n",
       " 'kuntum': 232,\n",
       " 'pisah': 337,\n",
       " 'pakcoy': 311,\n",
       " 'bag': 26,\n",
       " 'gls': 137,\n",
       " 'tauge': 434,\n",
       " 'cemplung': 93,\n",
       " 'tangkai': 429,\n",
       " 'tebal': 435,\n",
       " 'bulat': 76,\n",
       " 'asa': 15,\n",
       " 'lepas': 253,\n",
       " 'pedesnya': 324,\n",
       " 'an': 8,\n",
       " 'skip': 409,\n",
       " 'kupas': 234,\n",
       " 'lap': 241,\n",
       " 'roti': 354,\n",
       " 'panir': 314,\n",
       " 'bread': 67,\n",
       " 'crumb': 106,\n",
       " 'petis': 331,\n",
       " 'rajang': 349,\n",
       " 'marah': 271,\n",
       " 'jengkol': 172,\n",
       " 'egg': 118,\n",
       " 'bonggol': 64,\n",
       " 'brokoli': 69,\n",
       " 'serah': 396,\n",
       " 'kancing': 185,\n",
       " 'kuping': 235,\n",
       " 'bakso': 30,\n",
       " 'seafood': 382,\n",
       " 'wedges': 474,\n",
       " 'penuh': 327,\n",
       " 'wajib': 473,\n",
       " 'rutinitas': 359,\n",
       " 'hihihi': 148,\n",
       " 'hihi': 147,\n",
       " 'sayap': 377,\n",
       " 'kornet': 219,\n",
       " 'prei': 342,\n",
       " 'jumput': 177,\n",
       " 'udang': 460,\n",
       " 'kucai': 225,\n",
       " 'enak': 121,\n",
       " 'bebek': 47,\n",
       " 'asli': 18,\n",
       " 'baba': 23,\n",
       " 'cacah': 87,\n",
       " 'sosis': 412,\n",
       " 'cheedar': 99,\n",
       " 'mozarela': 292,\n",
       " 'garamsecukupnya': 129,\n",
       " 'beli': 49,\n",
       " 'bngkus': 60,\n",
       " 'saji': 363,\n",
       " 'manggoreng': 269,\n",
       " 'kobe': 214,\n",
       " 'lombok': 260,\n",
       " 'ulek': 466,\n",
       " 'ebi': 117,\n",
       " 'racik': 347,\n",
       " 'bakwan': 31,\n",
       " 'pindang': 334,\n",
       " 'abc': 0,\n",
       " 'isi': 164,\n",
       " 'labu': 237,\n",
       " 'siam': 404,\n",
       " 'terong': 444,\n",
       " 'ungu': 467,\n",
       " 'semangit': 394,\n",
       " 'seduh': 389,\n",
       " 'tiris': 449,\n",
       " 'sisir': 407,\n",
       " 'raja': 348,\n",
       " 'ambil': 6,\n",
       " 'sebentar': 383,\n",
       " 'baking': 29,\n",
       " 'powder': 341,\n",
       " 'karageenan': 190,\n",
       " 'kenyal': 206,\n",
       " 'es': 122,\n",
       " 'batu': 42,\n",
       " 'keping': 208,\n",
       " 'super': 424,\n",
       " 'crispy': 105,\n",
       " 'ayak': 21,\n",
       " 'picin': 332,\n",
       " 'ltr': 261,\n",
       " 'kepala': 207,\n",
       " 'mayonaise': 277,\n",
       " 'mayumi': 278,\n",
       " 'mutiara': 297,\n",
       " 'tekwan': 437,\n",
       " 'brown': 70,\n",
       " 'sugar': 421,\n",
       " 'dingin': 116,\n",
       " 'kanji': 187,\n",
       " 'bihun': 55,\n",
       " 'vaname': 471,\n",
       " 'oregano': 307}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kbest_feature = {} \n",
    "\n",
    "for (k,v) in tf_idf_X.vocabulary_.items():    \n",
    "    if k in selected_feature:                 \n",
    "        kbest_feature[k] = v  \n",
    "        \n",
    "kbest_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "119ff6ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abc</th>\n",
       "      <th>acar</th>\n",
       "      <th>adas</th>\n",
       "      <th>adon</th>\n",
       "      <th>air</th>\n",
       "      <th>al</th>\n",
       "      <th>ambil</th>\n",
       "      <th>amis</th>\n",
       "      <th>an</th>\n",
       "      <th>angciu</th>\n",
       "      <th>...</th>\n",
       "      <th>utama</th>\n",
       "      <th>utuh</th>\n",
       "      <th>vaname</th>\n",
       "      <th>vetsin</th>\n",
       "      <th>wajib</th>\n",
       "      <th>wedges</th>\n",
       "      <th>wijen</th>\n",
       "      <th>wortel</th>\n",
       "      <th>ya</th>\n",
       "      <th>zaitun</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.117864</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.091114</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.218798</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.176830</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.117644</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.328494</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.113208</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.115222</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>103 rows × 479 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     abc  acar  adas  adon       air   al  ambil  amis   an  angciu  ...  \\\n",
       "0    0.0   0.0   0.0   0.0  0.117864  0.0    0.0   0.0  0.0     0.0  ...   \n",
       "1    0.0   0.0   0.0   0.0  0.091114  0.0    0.0   0.0  0.0     0.0  ...   \n",
       "2    0.0   0.0   0.0   0.0  0.176830  0.0    0.0   0.0  0.0     0.0  ...   \n",
       "3    0.0   0.0   0.0   0.0  0.000000  0.0    0.0   0.0  0.0     0.0  ...   \n",
       "4    0.0   0.0   0.0   0.0  0.000000  0.0    0.0   0.0  0.0     0.0  ...   \n",
       "..   ...   ...   ...   ...       ...  ...    ...   ...  ...     ...  ...   \n",
       "98   0.0   0.0   0.0   0.0  0.117644  0.0    0.0   0.0  0.0     0.0  ...   \n",
       "99   0.0   0.0   0.0   0.0  0.113208  0.0    0.0   0.0  0.0     0.0  ...   \n",
       "100  0.0   0.0   0.0   0.0  0.115222  0.0    0.0   0.0  0.0     0.0  ...   \n",
       "101  0.0   0.0   0.0   0.0  0.000000  0.0    0.0   0.0  0.0     0.0  ...   \n",
       "102  0.0   0.0   0.0   0.0  0.000000  0.0    0.0   0.0  0.0     0.0  ...   \n",
       "\n",
       "     utama  utuh    vaname  vetsin  wajib  wedges  wijen  wortel        ya  \\\n",
       "0      0.0   0.0  0.000000     0.0    0.0     0.0    0.0     0.0  0.000000   \n",
       "1      0.0   0.0  0.000000     0.0    0.0     0.0    0.0     0.0  0.218798   \n",
       "2      0.0   0.0  0.000000     0.0    0.0     0.0    0.0     0.0  0.000000   \n",
       "3      0.0   0.0  0.000000     0.0    0.0     0.0    0.0     0.0  0.000000   \n",
       "4      0.0   0.0  0.000000     0.0    0.0     0.0    0.0     0.0  0.000000   \n",
       "..     ...   ...       ...     ...    ...     ...    ...     ...       ...   \n",
       "98     0.0   0.0  0.328494     0.0    0.0     0.0    0.0     0.0  0.000000   \n",
       "99     0.0   0.0  0.000000     0.0    0.0     0.0    0.0     0.0  0.000000   \n",
       "100    0.0   0.0  0.000000     0.0    0.0     0.0    0.0     0.0  0.000000   \n",
       "101    0.0   0.0  0.000000     0.0    0.0     0.0    0.0     0.0  0.000000   \n",
       "102    0.0   0.0  0.000000     0.0    0.0     0.0    0.0     0.0  0.000000   \n",
       "\n",
       "     zaitun  \n",
       "0       0.0  \n",
       "1       0.0  \n",
       "2       0.0  \n",
       "3       0.0  \n",
       "4       0.0  \n",
       "..      ...  \n",
       "98      0.0  \n",
       "99      0.0  \n",
       "100     0.0  \n",
       "101     0.0  \n",
       "102     0.0  \n",
       "\n",
       "[103 rows x 479 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_selected_feature = pd.DataFrame(X_kbest_features, columns=selected_feature)\n",
    "data_selected_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0e577d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_selected_feature.to_csv('data_selected_feature.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6d9e6aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('kbest_feature.pickle', 'wb') as output:\n",
    "    pickle.dump(kbest_feature, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ab60ce6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7bf60a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(data_tf_idf_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c86076d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size = 0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "92f8c2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c528500b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "# classifier = KNeighborsClassifier(n_neighbors = 8)\n",
    "# classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c9d90c2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiOutputRegressor(estimator=Ridge(random_state=123))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "multi_output_clf = MultiOutputRegressor(Ridge(random_state=123))\n",
    "multi_output_clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "448775d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7012c97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = multi_output_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "541bc386",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from numpy import absolute\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "\n",
    "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "afdde63d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.011 (0.001)\n"
     ]
    }
   ],
   "source": [
    "n_scores = cross_val_score(multi_output_clf, X_train, y_train, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1)\n",
    "\n",
    "n_scores = absolute(n_scores)\n",
    "\n",
    "print('MAE: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5d244a07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: [[ 2.19477494e-01  3.29489967e-01  8.15600360e-01 ... -2.90545028e-03\n",
      "   9.64022632e-01  4.99224881e-02]\n",
      " [ 8.43368646e-01  5.64675313e-01  3.28040418e-01 ...  5.53385034e-02\n",
      "   1.36536046e-01  6.30310630e-01]\n",
      " [-1.04499819e+00 -8.83771319e-01  7.67113096e-01 ...  4.82597952e-01\n",
      "   4.20755200e-01  1.63888893e+00]\n",
      " ...\n",
      " [ 1.05533584e+00  6.93456049e-01 -4.02886049e-02 ...  1.77556598e+00\n",
      "   7.86215852e-01  1.40686786e+00]\n",
      " [-1.21333813e+00 -3.79517516e-01  4.35986196e-01 ...  9.66220863e-01\n",
      "   3.32107876e+00 -2.69836174e+00]\n",
      " [-8.13514715e-01 -1.02528191e+00  7.01965245e-01 ... -2.74046516e-01\n",
      "   8.56770375e-01  1.86000596e+00]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "from sklearn.multioutput import RegressorChain\n",
    "from sklearn.svm import LinearSVR\n",
    "\n",
    "X_train, y_train = make_regression(n_samples=1000, n_features=10, n_informative=5, n_targets=2, random_state=1, noise=0.5)\n",
    "\n",
    "model = LinearSVR()\n",
    "\n",
    "row = X_train\n",
    "\n",
    "print('Predicted: %s' % row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f926c0f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model_1.joblib']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump   \n",
    "model = multi_output_clf.fit(X_train, y_train)   \n",
    "\n",
    "dump(model, filename='model_1.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1e16d0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "# result = confusion_matrix(y_test, y_pred)\n",
    "# print(\"Confusion Matrix:\")\n",
    "# print(result)\n",
    "# result1 = classification_report(y_test, y_pred)\n",
    "# print(\"Classification Report:\",)\n",
    "# print (result1)\n",
    "# result2 = accuracy_score(y_test,y_pred)\n",
    "# print(\"Accuracy:\",result2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5cae1f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cfbde9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y,test_size = 0.4)\n",
    "# from sklearn.neighbors import KNeighborsRegressor\n",
    "# knnr = KNeighborsRegressor(n_neighbors = 10)\n",
    "# knnr.fit(X_train, y_train)\n",
    "# y_pred = knnr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5dbebfaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mse = np.power(y-knnr.predict(X),2).mean()\n",
    "# print (\"The MSE is:\",mse)\n",
    "# import math\n",
    "# rmse = math.sqrt(mse)\n",
    "# print(\"The RMSE is:\", rmse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
